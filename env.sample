YOUR_NAME=John
LANGUAGE=en
INTERUPT_MANUALLY=True
AUTO_START_TRANSCRIPTION=False
AUTO_SUMMARIZE_ON_STOP=False
# Enable internet search for assistant answers to user-entered custom prompts
ASSISTANT_ENABLE_WEB_SEARCH_FOR_CUSTOM_PROMPTS=True
OPENAI_API_KEY=
# Assistant model (optional)
OPENAI_MODEL_FOR_ASSISTANT=gpt-5-mini
# Comment out if you don't want suggestions from AI. Set the right vector store ID with the right knowledge (should start wtith vs_*)
OPENAI_VECTOR_STORE_ID_FOR_ANSWERS=
# Live assistant panels (triggered by output-device transcription only)
ASSISTANT_LIVE_ANSWERS_ENABLED=False
ASSISTANT_LIVE_SUGGESTIONS_ENABLED=False
ASSISTANT_LIVE_EXPLANATION_ENABLED=False
ASSISTANT_LIVE_FACTS_ENABLED=False
# Assistant prompt templates (use \n for line breaks)
ASSISTANT_PROMPT_BASE=You are helping user with name '{your_name}'.\nThe user is in a live meeting and shares raw transcript snippets. Treat earlier messages as context but focus your reply on the most recent entry. Keep responses in plain text (no Markdown) and limit yourself to at most three sentences. Do not include document references, filenames, or URLs. Avoid repeating previous guidance.
ASSISTANT_PROMPT_ANSWER_QUESTION=Address the most recent message directly. When you need additional context, perform a file search before responding. If the message is not a question or you lack sufficient information, reply with '---'. Do not ask the user follow-up questions.
ASSISTANT_PROMPT_SUGGEST_QUESTIONS=Produce one to three concise questions the user could ask next, each on its own line. Use available context and perform a file search first if it helps craft better prompts.
ASSISTANT_PROMPT_EXPLAIN_IT=Explain key concepts, decisions, or reasoning referenced in the latest message so the user understands them quickly. Draw on file search when needed. Provide clear, practical insight within three sentences.
ASSISTANT_PROMPT_GET_FACTS=Investigate the latest message by performing an up-to-date internet search along with any relevant file search. Return a brief factual summary that highlights the most relevant information you find.
ASSISTANT_PROMPT_CUSTOM_PROMPT=The user has asked a specific question during the meeting. Address their question directly and comprehensively. Perform a file search or web search if additional information would help. Provide a clear, actionable answer.
# Comment out if you don't want to use OpenAI for transcription, but use local model instead
OPENAI_MODEL_FOR_TRANSCRIPT=gpt-4o-mini-transcribe
#OPENAI_MODEL_FOR_TRANSCRIPT=gpt-4o-transcribe
# UI font sizing
AGENT_FONT_SIZE=14
DEFAULT_FONT_SIZE=10
# Logging
LOG_LEVEL=INFO
LOG_FILE_MAX_MB=5
LOG_FILE_BACKUP_COUNT=5
# Audio segmentation tuning
RECORD_SECONDS=300
SILENCE_THRESHOLD=50
SILENCE_DURATION=1.0
FRAME_DURATION_MS=100
OUTPUT_DIR=output
TEMP_DIR=tmp
SUMMARIES_DIR=output_summaries
# Assistant API resilience
ASSISTANT_API_TIMEOUT_SECONDS=60
ASSISTANT_API_MAX_RETRIES=3
ASSISTANT_API_RETRY_BASE_SECONDS=1.0
ASSISTANT_SUMMARY_TIMEOUT_SECONDS=120
ASSISTANT_TITLE_TIMEOUT_SECONDS=30
# Transcription API resilience
TRANSCRIBE_API_TIMEOUT_SECONDS=60
TRANSCRIBE_API_MAX_RETRIES=3
TRANSCRIBE_API_RETRY_BASE_SECONDS=1.0
# Transcript filtering (artifact/hallucination control)
TRANSCRIPT_FILTER_MIN_CHARS=2
# Comma-separated optional overrides/extensions:
# TRANSCRIPT_FILTER_EXACT="bye., um"
# TRANSCRIPT_FILTER_PREFIXES="thanks for watching, thank you for joining"
# TRANSCRIPT_FILTER_CONTAINS="please subscribe to my channel, amara.org"
# TRANSCRIPT_FILTER_REGEX="\\bpromo\\b, ^[\\W_]+$"
# Complex words where transcriber usually fails:
KEYWORDS="CocaCola, Pepsi, McDonald's, KFC, Burger King"
# Path to a markdown/text file with background context included in every AI call
CONTEXT_FILE=context.md
